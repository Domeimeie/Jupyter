{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa66f200-a4b8-41db-b2ae-7ddef4b97ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 170M/170M [00:07<00:00, 22.5MB/s]\n",
      "Train 1: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [00:10<00:00, 37.20it/s, acc=39.4, loss=1.66]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss 1.6605, acc 39.37% | Val loss 1.4456, acc 46.71%\n",
      "Saved new best model (val acc 46.71%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 2: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [00:03<00:00, 126.00it/s, acc=52.1, loss=1.34]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train loss 1.3352, acc 52.06% | Val loss 1.4071, acc 50.06%\n",
      "Saved new best model (val acc 50.06%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 3: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [00:03<00:00, 119.93it/s, acc=56.9, loss=1.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train loss 1.2050, acc 56.88% | Val loss 1.2258, acc 55.32%\n",
      "Saved new best model (val acc 55.32%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [00:03<00:00, 120.01it/s, acc=59.7, loss=1.14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train loss 1.1378, acc 59.70% | Val loss 1.1411, acc 58.96%\n",
      "Saved new best model (val acc 58.96%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 5: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [00:03<00:00, 120.84it/s, acc=61.3, loss=1.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss 1.0848, acc 61.29% | Val loss 1.2236, acc 56.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 6: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [00:03<00:00, 117.13it/s, acc=63.4, loss=1.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train loss 1.0374, acc 63.41% | Val loss 1.1371, acc 59.04%\n",
      "Saved new best model (val acc 59.04%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 7: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [00:03<00:00, 116.66it/s, acc=64.6, loss=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train loss 1.0046, acc 64.64% | Val loss 1.0778, acc 62.28%\n",
      "Saved new best model (val acc 62.28%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 8: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [00:03<00:00, 118.40it/s, acc=65.9, loss=0.972]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train loss 0.9717, acc 65.90% | Val loss 0.9868, acc 64.42%\n",
      "Saved new best model (val acc 64.42%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 9: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [00:03<00:00, 114.80it/s, acc=66.9, loss=0.942]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train loss 0.9423, acc 66.89% | Val loss 1.0437, acc 63.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [00:03<00:00, 114.55it/s, acc=67.6, loss=0.922]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train loss 0.9223, acc 67.64% | Val loss 1.0304, acc 64.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 11: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [00:03<00:00, 115.16it/s, acc=68.8, loss=0.896]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train loss 0.8965, acc 68.76% | Val loss 0.9729, acc 65.36%\n",
      "Saved new best model (val acc 65.36%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 12: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [00:03<00:00, 116.38it/s, acc=69.7, loss=0.869]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train loss 0.8691, acc 69.68% | Val loss 0.9408, acc 67.09%\n",
      "Saved new best model (val acc 67.09%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 13: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [00:03<00:00, 117.43it/s, acc=70.8, loss=0.848]\n"
     ]
    }
   ],
   "source": [
    "# train_cifar.py\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# -----------------------\n",
    "# Reproducibility / device\n",
    "# -----------------------\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# -----------------------\n",
    "# Hyperparams\n",
    "# -----------------------\n",
    "batch_size = 128\n",
    "num_epochs = 30\n",
    "learning_rate = 0.01\n",
    "num_workers = 4  # set 0 on Windows or when debugging\n",
    "save_dir = \"./checkpoints\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# -----------------------\n",
    "# Data transforms + loaders\n",
    "# -----------------------\n",
    "cifar_mean = [0.4914, 0.4822, 0.4465]\n",
    "cifar_std  = [0.2470, 0.2435, 0.2616]\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cifar_mean, cifar_std),\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cifar_mean, cifar_std),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=train_transforms)\n",
    "val_dataset   = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "# -----------------------\n",
    "# Model: small CNN\n",
    "# -----------------------\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 16x16\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 8x8\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((1,1)),  # 1x1\n",
    "        )\n",
    "        self.classifier = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "model = SimpleCNN(num_classes=10).to(device)\n",
    "\n",
    "# -----------------------\n",
    "# Loss, optimizer, scheduler\n",
    "# -----------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\n",
    "\n",
    "# -----------------------\n",
    "# Train / validate loops\n",
    "# -----------------------\n",
    "def train_one_epoch(epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pbar = tqdm(train_loader, desc=f\"Train {epoch}\")\n",
    "    for inputs, targets in pbar:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        pbar.set_postfix(loss=running_loss/total, acc=100.*correct/total)\n",
    "\n",
    "    return running_loss / total, 100.*correct/total\n",
    "\n",
    "def validate(epoch):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    return running_loss/total, 100.*correct/total\n",
    "\n",
    "best_val_acc = 0.0\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    train_loss, train_acc = train_one_epoch(epoch)\n",
    "    val_loss, val_acc = validate(epoch)\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {epoch}: Train loss {train_loss:.4f}, acc {train_acc:.2f}% | Val loss {val_loss:.4f}, acc {val_acc:.2f}%\")\n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state': model.state_dict(),\n",
    "            'optimizer_state': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "        }, os.path.join(save_dir, \"best_cifar_model.pth\"))\n",
    "        print(f\"Saved new best model (val acc {val_acc:.2f}%)\")\n",
    "\n",
    "print(\"Training finished. Best val acc:\", best_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332bad5d-af15-42b8-9017-8c5a64294b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best checkpoint\n",
    "checkpoint = torch.load(\"./checkpoints/best_cifar_model.pth\", map_location=device)\n",
    "\n",
    "model = SimpleCNN(num_classes=10).to(device)\n",
    "model.load_state_dict(checkpoint[\"model_state\"])\n",
    "model.eval()\n",
    "\n",
    "print(\"Loaded model from epoch:\", checkpoint[\"epoch\"], \"with val acc:\", checkpoint[\"val_acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278a92fb-78dd-438a-a6ba-7edd987eb762",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=val_transforms  # same normalization you defined earlier\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "\n",
    "print(f\"Test accuracy: {100. * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0376326-883a-40dc-8cf7-4ea50ed98643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# CIFAR-10 classes\n",
    "classes = ['airplane','automobile','bird','cat','deer',\n",
    "           'dog','frog','horse','ship','truck']\n",
    "\n",
    "# Load best model\n",
    "checkpoint = torch.load(\"./checkpoints/best_cifar_model.pth\", map_location=device)\n",
    "model = SimpleCNN(num_classes=10).to(device)\n",
    "model.load_state_dict(checkpoint['model_state'])\n",
    "model.eval()\n",
    "\n",
    "# Test dataset\n",
    "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=val_transforms)\n",
    "\n",
    "# Function to display predictions with color feedback\n",
    "def show_predictions(model, dataset, num_images=12):\n",
    "    model.eval()\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        img, label = dataset[i]\n",
    "        with torch.no_grad():\n",
    "            output = model(img.unsqueeze(0).to(device))\n",
    "            pred = output.argmax(1).item()\n",
    "        \n",
    "        # Unnormalize image\n",
    "        img_np = img.permute(1,2,0).cpu().numpy() * np.array(cifar_std) + np.array(cifar_mean)\n",
    "        img_np = np.clip(img_np, 0, 1)\n",
    "        \n",
    "        axes[i].imshow(img_np)\n",
    "        axes[i].axis(\"off\")\n",
    "        \n",
    "        # Set color: green if correct, red if wrong\n",
    "        color = 'green' if pred == label else 'red'\n",
    "        axes[i].set_title(f\"P: {classes[pred]}\\nT: {classes[label]}\", color=color)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show predictions\n",
    "show_predictions(model, test_dataset, num_images=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43c325c-7ff3-489c-8105-39c160f3400d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
