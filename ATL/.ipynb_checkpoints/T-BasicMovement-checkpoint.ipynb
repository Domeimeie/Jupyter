{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e0d140e-d46d-455c-a828-bd36e21fbaf9",
   "metadata": {},
   "source": [
    "# Reinforcement Learning Modell "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534403f2-c4a3-4b8e-8810-837c585e13ea",
   "metadata": {},
   "source": [
    "# Godot Connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a907490-767a-4d9a-bc88-ef93e5b24bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 100 environments.\n",
      "Expecting Godot instances on ports: [5000, 5001, 5002, 5003, 5004, 5005, 5006, 5007, 5008, 5009, 5010, 5011, 5012, 5013, 5014, 5015, 5016, 5017, 5018, 5019, 5020, 5021, 5022, 5023, 5024, 5025, 5026, 5027, 5028, 5029, 5030, 5031, 5032, 5033, 5034, 5035, 5036, 5037, 5038, 5039, 5040, 5041, 5042, 5043, 5044, 5045, 5046, 5047, 5048, 5049, 5050, 5051, 5052, 5053, 5054, 5055, 5056, 5057, 5058, 5059, 5060, 5061, 5062, 5063, 5064, 5065, 5066, 5067, 5068, 5069, 5070, 5071, 5072, 5073, 5074, 5075, 5076, 5077, 5078, 5079, 5080, 5081, 5082, 5083, 5084, 5085, 5086, 5087, 5088, 5089, 5090, 5091, 5092, 5093, 5094, 5095, 5096, 5097, 5098, 5099]\n",
      "Using device: cpu\n",
      "[CHECKPOINT] No checkpoint found, starting fresh.\n",
      "Connected to env on port 5000\n",
      "Connected to env on port 5001\n",
      "Connected to env on port 5002\n",
      "Connected to env on port 5003\n",
      "Connected to env on port 5004\n",
      "Connected to env on port 5005\n",
      "Connected to env on port 5006\n",
      "Connected to env on port 5007\n",
      "Connected to env on port 5008\n",
      "Connected to env on port 5009\n",
      "Connected to env on port 5010\n",
      "Connected to env on port 5011\n",
      "Connected to env on port 5012\n",
      "Connected to env on port 5013\n",
      "Connected to env on port 5014\n",
      "Connected to env on port 5015\n",
      "Connected to env on port 5016\n",
      "Connected to env on port 5017\n",
      "Connected to env on port 5018\n",
      "Connected to env on port 5019\n",
      "Connected to env on port 5020\n",
      "Connected to env on port 5021\n",
      "Connected to env on port 5022\n",
      "Connected to env on port 5023\n",
      "Connected to env on port 5024\n",
      "Connected to env on port 5025\n",
      "Connected to env on port 5026\n",
      "Connected to env on port 5027\n",
      "Connected to env on port 5028\n",
      "Connected to env on port 5029\n",
      "Connected to env on port 5030\n",
      "Connected to env on port 5031\n",
      "Connected to env on port 5032\n",
      "Connected to env on port 5033\n",
      "Connected to env on port 5034\n",
      "Connected to env on port 5035\n",
      "Connected to env on port 5036\n",
      "Connected to env on port 5037\n",
      "Connected to env on port 5038\n",
      "Connected to env on port 5039\n",
      "Connected to env on port 5040\n",
      "Connected to env on port 5041\n",
      "Connected to env on port 5042\n",
      "Connected to env on port 5043\n",
      "Connected to env on port 5044\n",
      "Connected to env on port 5045\n",
      "Connected to env on port 5046\n",
      "Connected to env on port 5047\n",
      "Connected to env on port 5048\n",
      "Connected to env on port 5049\n",
      "Connected to env on port 5050\n",
      "Connected to env on port 5051\n",
      "Connected to env on port 5052\n",
      "Connected to env on port 5053\n",
      "Connected to env on port 5054\n",
      "Connected to env on port 5055\n",
      "Connected to env on port 5056\n",
      "Connected to env on port 5057\n",
      "Connected to env on port 5058\n",
      "Connected to env on port 5059\n",
      "Connected to env on port 5060\n",
      "Connected to env on port 5061\n",
      "Connected to env on port 5062\n",
      "Connected to env on port 5063\n",
      "Connected to env on port 5064\n",
      "Connected to env on port 5065\n",
      "Connected to env on port 5066\n",
      "Connected to env on port 5067\n",
      "Connected to env on port 5068\n",
      "Connected to env on port 5069\n",
      "Connected to env on port 5070\n",
      "Connected to env on port 5071\n",
      "Connected to env on port 5072\n",
      "Connected to env on port 5073\n",
      "Connected to env on port 5074\n",
      "Connected to env on port 5075\n",
      "Connected to env on port 5076\n",
      "Connected to env on port 5077\n",
      "Connected to env on port 5078\n",
      "Connected to env on port 5079\n",
      "Connected to env on port 5080\n",
      "Connected to env on port 5081\n",
      "Connected to env on port 5082\n",
      "Connected to env on port 5083\n",
      "Connected to env on port 5084\n",
      "Connected to env on port 5085\n",
      "Connected to env on port 5086\n",
      "Connected to env on port 5087\n",
      "Connected to env on port 5088\n",
      "Connected to env on port 5089\n",
      "Connected to env on port 5090\n",
      "Connected to env on port 5091\n",
      "Connected to env on port 5092\n",
      "Connected to env on port 5093\n",
      "Connected to env on port 5094\n",
      "Connected to env on port 5095\n",
      "Connected to env on port 5096\n",
      "Connected to env on port 5097\n",
      "Connected to env on port 5098\n",
      "Connected to env on port 5099\n",
      "All envs connected, starting training loop...\n",
      "[CHECKPOINT] Saved to tank_dqn_checkpoint.pt\n",
      "[ENV 42] episode 0 return = 6.671, eps=0.010\n",
      "[CHECKPOINT] Saved to tank_dqn_checkpoint.pt\n",
      "[CHECKPOINT] Saved to tank_dqn_checkpoint.pt\n",
      "[CHECKPOINT] Saved to tank_dqn_checkpoint.pt\n",
      "[CHECKPOINT] Saved to tank_dqn_checkpoint.pt\n",
      "[CHECKPOINT] Saved to tank_dqn_checkpoint.pt\n",
      "[CHECKPOINT] Saved to tank_dqn_checkpoint.pt\n",
      "[CHECKPOINT] Saved to tank_dqn_checkpoint.pt\n",
      "[CHECKPOINT] Saved to tank_dqn_checkpoint.pt\n",
      "[CHECKPOINT] Saved to tank_dqn_checkpoint.pt\n",
      "[ENV 57] episode 0 return = 20.685, eps=0.010\n",
      "[CHECKPOINT] Saved to tank_dqn_checkpoint.pt\n",
      "[CHECKPOINT] Saved to tank_dqn_checkpoint.pt\n",
      "[CHECKPOINT] Saved to tank_dqn_checkpoint.pt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 367\u001b[39m\n\u001b[32m    365\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    366\u001b[39m     load_checkpoint()\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     \u001b[43mreceive_loop_multi_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 362\u001b[39m, in \u001b[36mreceive_loop_multi_env\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    359\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    361\u001b[39m buffers[env_idx] += chunk.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m362\u001b[39m \u001b[43m_process_buffer_for_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 327\u001b[39m, in \u001b[36m_process_buffer_for_env\u001b[39m\u001b[34m(env_idx, sock)\u001b[39m\n\u001b[32m    325\u001b[39m buf = buf[idx:]\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[43mon_message_multi_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    329\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError in on_message for env \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 266\u001b[39m, in \u001b[36mon_message_multi_env\u001b[39m\u001b[34m(env_idx, sock, message)\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prev_s \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m prev_a \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    265\u001b[39m     store_transition(prev_s, prev_a, reward, state, done)\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     loss = \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    268\u001b[39m     loss = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 239\u001b[39m, in \u001b[36mtrain_step\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    236\u001b[39m     targets = rewards + GAMMA * max_next_q * (\u001b[32m1.0\u001b[39m - dones)\n\u001b[32m    238\u001b[39m loss = loss_fn(q_values, targets)\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    240\u001b[39m loss.backward()\n\u001b[32m    241\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.14/site-packages/torch/_compile.py:53\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     50\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive, wrapping=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     51\u001b[39m     fn.__dynamo_disable = disable_fn  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.14/site-packages/torch/_dynamo/eval_frame.py:1044\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1042\u001b[39m _maybe_set_eval_frame(_callback_from_stance(\u001b[38;5;28mself\u001b[39m.callback))\n\u001b[32m   1043\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1046\u001b[39m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.14/site-packages/torch/optim/optimizer.py:1030\u001b[39m, in \u001b[36mOptimizer.zero_grad\u001b[39m\u001b[34m(self, set_to_none)\u001b[39m\n\u001b[32m   1027\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1028\u001b[39m     per_device_and_dtype_grads = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1030\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprofiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecord_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_zero_grad_profile_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_groups\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparams\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.14/site-packages/torch/autograd/profiler.py:801\u001b[39m, in \u001b[36mrecord_function.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_value, traceback)\u001b[39m\n\u001b[32m    799\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.jit.is_scripting():\n\u001b[32m    800\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch._C.DisableTorchFunctionSubclass():\n\u001b[32m--> \u001b[39m\u001b[32m801\u001b[39m         \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprofiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_record_function_exit\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_RecordFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    803\u001b[39m     torch.ops.profiler._record_function_exit(record)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.14/site-packages/torch/_ops.py:1069\u001b[39m, in \u001b[36mTorchBindOpOverload.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1068\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, /, *args: _P.args, **kwargs: _P.kwargs) -> _T:\n\u001b[32m-> \u001b[39m\u001b[32m1069\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_must_dispatch_in_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1070\u001b[39m         \u001b[38;5;66;03m# When any inputs are FakeScriptObject, we need to\u001b[39;00m\n\u001b[32m   1071\u001b[39m         \u001b[38;5;66;03m# skip c++ dispatcher and dispatch in python through _get_dispatch of python_dispatcher\u001b[39;00m\n\u001b[32m   1072\u001b[39m         \u001b[38;5;66;03m# because C++ dispatcher will check the schema and cannot recognize FakeScriptObject.\u001b[39;00m\n\u001b[32m   1073\u001b[39m         \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m   1074\u001b[39m         \u001b[38;5;66;03m# Note:\u001b[39;00m\n\u001b[32m   1075\u001b[39m         \u001b[38;5;66;03m# 1. We only register the torchbind op temporarily as effectful op because we only want\u001b[39;00m\n\u001b[32m   1076\u001b[39m         \u001b[38;5;66;03m#    the effect token functionalization logic to be applied during tracing. Otherwise, the behavior\u001b[39;00m\n\u001b[32m   1077\u001b[39m         \u001b[38;5;66;03m#    of the eagerly executing the op might change after tracing.\u001b[39;00m\n\u001b[32m   1078\u001b[39m         \u001b[38;5;66;03m# 2. We don't want to register the op as effectful for all torchbind ops in ctor because this might\u001b[39;00m\n\u001b[32m   1079\u001b[39m         \u001b[38;5;66;03m#    cause unexpected behavior for some autograd.profiler ops e.g. profiler._record_function_exit._RecordFunction.\u001b[39;00m\n\u001b[32m   1080\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._register_as_effectful_op_temporarily():\n\u001b[32m   1081\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dispatch_in_python(\n\u001b[32m   1082\u001b[39m                 \u001b[38;5;28mself\u001b[39m._fallthrough_keys(), *args, **kwargs\n\u001b[32m   1083\u001b[39m             )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.14/site-packages/torch/_ops.py:1129\u001b[39m, in \u001b[36m_must_dispatch_in_python\u001b[39m\u001b[34m(args, kwargs)\u001b[39m\n\u001b[32m   1128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_must_dispatch_in_python\u001b[39m(args, kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m1129\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpytree\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtree_any\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m            \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_library\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfake_class_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFakeScriptObject\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.14/site-packages/torch/utils/_pytree.py:1630\u001b[39m, in \u001b[36mtree_any\u001b[39m\u001b[34m(pred, tree, is_leaf)\u001b[39m\n\u001b[32m   1626\u001b[39m     flat_args = tree_iter(tree, is_leaf=is_leaf)\n\u001b[32m   1627\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mmap\u001b[39m(pred, flat_args))\n\u001b[32m-> \u001b[39m\u001b[32m1630\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtree_any\u001b[39m(\n\u001b[32m   1631\u001b[39m     pred: Callable[[Any], \u001b[38;5;28mbool\u001b[39m],\n\u001b[32m   1632\u001b[39m     tree: PyTree,\n\u001b[32m   1633\u001b[39m     is_leaf: Optional[Callable[[PyTree], \u001b[38;5;28mbool\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1634\u001b[39m ) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m   1635\u001b[39m     flat_args = tree_iter(tree, is_leaf=is_leaf)\n\u001b[32m   1636\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28mmap\u001b[39m(pred, flat_args))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import json\n",
    "from typing import Any, Dict, List, Tuple\n",
    "import random\n",
    "from collections import deque\n",
    "import os\n",
    "import select\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# ===========================\n",
    "#      ENVIRONMENT CONFIG\n",
    "# ===========================\n",
    "\n",
    "HOST = \"127.0.0.1\"\n",
    "\n",
    "# How many parallel Godot environments to train with\n",
    "N_ENVS = 20 \n",
    "\n",
    "# Port base for Godot instances\n",
    "BASE_PORT = 5000\n",
    "\n",
    "# Generate ports based on environments\n",
    "ENV_PORTS = [BASE_PORT + i for i in range(N_ENVS)]\n",
    "\n",
    "print(f\"Training with {N_ENVS} environments.\")\n",
    "print(f\"Expecting Godot instances on ports: {ENV_PORTS}\")\n",
    "\n",
    "# ===========================\n",
    "#  RL / model config\n",
    "# ===========================\n",
    "\n",
    "# State vector: tank_x, tank_y, goal_x, goal_y, dx, dy  (all normalized)\n",
    "STATE_SIZE = 8\n",
    "\n",
    "# Discrete actions: (turn, throttle) with values in {-1, 0, 1}\n",
    "# Godot will feed these into setTurn() and setDirection().\n",
    "ACTIONS: List[Dict[str, float]] = [\n",
    "    {\"turn\": -1.0, \"throttle\":  1.0},  # left + forward\n",
    "    {\"turn\":  0.0, \"throttle\":  1.0},  # straight + forward\n",
    "    {\"turn\":  1.0, \"throttle\":  1.0},  # right + forward\n",
    "    {\"turn\":  0.0, \"throttle\":  0.0},  # stop\n",
    "    {\"turn\":  0.0, \"throttle\": -1.0},  # straight + backward\n",
    "]\n",
    "N_ACTIONS = len(ACTIONS)\n",
    "\n",
    "GAMMA = 0.99\n",
    "EPSILON_START = 0.2\n",
    "EPSILON_END = 0.01\n",
    "EPSILON_DECAY = 1e-4\n",
    "BATCH_SIZE = 32\n",
    "REPLAY_SIZE = 10_000\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "CHECKPOINT_PATH = \"tank_dqn_checkpoint.pt\"\n",
    "LOG_PATH = \"training_log.csv\"\n",
    "\n",
    "# ===========================\n",
    "#  Q-network\n",
    "# ===========================\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)  # [batch, output_dim] (Q-values for each action)\n",
    "\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "q_net = QNetwork(STATE_SIZE, N_ACTIONS).to(device)\n",
    "optimizer = optim.Adam(q_net.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "ReplayEntry = Tuple[List[float], int, float, List[float], bool]\n",
    "replay_buffer: deque[ReplayEntry] = deque(maxlen=REPLAY_SIZE)\n",
    "\n",
    "# Globals for RL bookkeeping (shared across envs)\n",
    "epsilon = EPSILON_START\n",
    "total_steps = 0\n",
    "\n",
    "# Per-env bookkeeping\n",
    "num_envs = len(ENV_PORTS)\n",
    "buffers: List[str] = [\"\"] * num_envs\n",
    "prev_states: List[List[float] | None] = [None] * num_envs\n",
    "prev_actions: List[int | None] = [None] * num_envs\n",
    "episode_returns: List[float] = [0.0] * num_envs\n",
    "episode_idxs: List[int] = [0] * num_envs\n",
    "\n",
    "decoder = json.JSONDecoder()\n",
    "\n",
    "# ===========================\n",
    "#  Checkpoint + logging\n",
    "# ===========================\n",
    "\n",
    "def save_checkpoint() -> None:\n",
    "    state = {\n",
    "        \"q_net\": q_net.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"epsilon\": epsilon,\n",
    "        \"total_steps\": total_steps,\n",
    "        \"episode_idxs\": episode_idxs,\n",
    "    }\n",
    "    torch.save(state, CHECKPOINT_PATH)\n",
    "    print(f\"[CHECKPOINT] Saved to {CHECKPOINT_PATH}\")\n",
    "\n",
    "\n",
    "def load_checkpoint() -> None:\n",
    "    global epsilon, total_steps, episode_idxs\n",
    "    if not os.path.exists(CHECKPOINT_PATH):\n",
    "        print(\"[CHECKPOINT] No checkpoint found, starting fresh.\")\n",
    "        return\n",
    "    state = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "    q_net.load_state_dict(state[\"q_net\"])\n",
    "    optimizer.load_state_dict(state[\"optimizer\"])\n",
    "    epsilon = state.get(\"epsilon\", epsilon)\n",
    "    total_steps = state.get(\"total_steps\", 0)\n",
    "    episode_idxs = state.get(\"episode_idxs\", episode_idxs)\n",
    "    print(f\"[CHECKPOINT] Loaded from {CHECKPOINT_PATH}, steps={total_steps}\")\n",
    "\n",
    "\n",
    "def log_episode_to_file(env_idx: int, ep_idx: int, ep_return: float, eps: float) -> None:\n",
    "    header_needed = not os.path.exists(LOG_PATH)\n",
    "    with open(LOG_PATH, \"a\") as f:\n",
    "        if header_needed:\n",
    "            f.write(\"env,episode,return,epsilon\\n\")\n",
    "        f.write(f\"{env_idx},{ep_idx},{ep_return},{eps}\\n\")\n",
    "\n",
    "\n",
    "# ===========================\n",
    "#  Networking helpers\n",
    "# ===========================\n",
    "\n",
    "def send_json(sock: socket.socket, payload: Dict[str, Any]) -> None:\n",
    "    data = json.dumps(payload)\n",
    "    sock.sendall(data.encode(\"utf-8\"))\n",
    "\n",
    "\n",
    "def connect_all_envs() -> List[socket.socket]:\n",
    "    socks: List[socket.socket] = []\n",
    "    for p in ENV_PORTS:\n",
    "        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        s.connect((HOST, p))\n",
    "        s.setblocking(False)\n",
    "        print(f\"Connected to env on port {p}\")\n",
    "        socks.append(s)\n",
    "    return socks\n",
    "\n",
    "\n",
    "# ===========================\n",
    "#  State / RL helpers\n",
    "# ===========================\n",
    "\n",
    "def build_state_vector(message: Dict[str, Any]) -> List[float]:\n",
    "    arena = message.get(\"arena\", {})\n",
    "    tank = message.get(\"tank\", {})\n",
    "    goal = message.get(\"goal\", {})\n",
    "\n",
    "    arena_w = float(arena.get(\"width\", 1.0))\n",
    "    arena_h = float(arena.get(\"height\", 1.0))\n",
    "\n",
    "    tank_x = float(tank.get(\"x\", 0.0))\n",
    "    tank_y = float(tank.get(\"y\", 0.0))\n",
    "    goal_x = float(goal.get(\"x\", 0.0))\n",
    "    goal_y = float(goal.get(\"y\", 0.0))\n",
    "\n",
    "    # NEW: orientation\n",
    "    theta = float(tank.get(\"rot\", 0.0))  # radians from Godot\n",
    "    cos_theta = math.cos(theta)\n",
    "    sin_theta = math.sin(theta)\n",
    "\n",
    "    # Normalize positions to [0, 1]\n",
    "    tank_x_n = tank_x / arena_w\n",
    "    tank_y_n = tank_y / arena_h\n",
    "    goal_x_n = goal_x / arena_w\n",
    "    goal_y_n = goal_y / arena_h\n",
    "\n",
    "    # Relative position tank -> goal, also normalized\n",
    "    dx = (goal_x - tank_x) / arena_w\n",
    "    dy = (goal_y - tank_y) / arena_h\n",
    "\n",
    "    # State: position, relative goal, orientation (cos, sin)\n",
    "    return [tank_x_n, tank_y_n, goal_x_n, goal_y_n, dx, dy, cos_theta, sin_theta]\n",
    "\n",
    "\n",
    "def select_action(state: List[float]) -> int:\n",
    "    global epsilon\n",
    "\n",
    "    epsilon = max(EPSILON_END, epsilon - EPSILON_DECAY)\n",
    "\n",
    "    if random.random() < epsilon:\n",
    "        return random.randrange(N_ACTIONS)\n",
    "\n",
    "    state_t = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        q_vals = q_net(state_t)\n",
    "    return int(torch.argmax(q_vals, dim=1).item())\n",
    "\n",
    "\n",
    "def store_transition(s: List[float], a: int, r: float, s_next: List[float], done: bool) -> None:\n",
    "    replay_buffer.append((s, a, r, s_next, done))\n",
    "\n",
    "\n",
    "def train_step() -> float | None:\n",
    "    global total_steps\n",
    "\n",
    "    if len(replay_buffer) < BATCH_SIZE:\n",
    "        return None\n",
    "\n",
    "    batch = random.sample(replay_buffer, BATCH_SIZE)\n",
    "\n",
    "    states = torch.tensor([b[0] for b in batch], dtype=torch.float32, device=device)\n",
    "    actions = torch.tensor([b[1] for b in batch], dtype=torch.int64, device=device)\n",
    "    rewards = torch.tensor([b[2] for b in batch], dtype=torch.float32, device=device)\n",
    "    next_states = torch.tensor([b[3] for b in batch], dtype=torch.float32, device=device)\n",
    "    dones = torch.tensor([b[4] for b in batch], dtype=torch.float32, device=device)\n",
    "\n",
    "    q_values = q_net(states)  # [B, N_ACTIONS]\n",
    "    q_values = q_values.gather(1, actions.unsqueeze(1)).squeeze(1)  # [B]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        next_q = q_net(next_states)\n",
    "        max_next_q = next_q.max(dim=1)[0]\n",
    "        targets = rewards + GAMMA * max_next_q * (1.0 - dones)\n",
    "\n",
    "    loss = loss_fn(q_values, targets)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_steps += 1\n",
    "    if total_steps % 1000 == 0:\n",
    "        save_checkpoint()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "# ===========================\n",
    "#  Per-env message handling\n",
    "# ===========================\n",
    "\n",
    "def on_message_multi_env(env_idx: int, sock: socket.socket, message: Dict[str, Any]) -> None:\n",
    "    state = build_state_vector(message)\n",
    "    reward = float(message.get(\"reward\", 0.0))\n",
    "    done = bool(message.get(\"done\", False))\n",
    "\n",
    "    episode_returns[env_idx] += reward\n",
    "\n",
    "    prev_s = prev_states[env_idx]\n",
    "    prev_a = prev_actions[env_idx]\n",
    "\n",
    "    if prev_s is not None and prev_a is not None:\n",
    "        store_transition(prev_s, prev_a, reward, state, done)\n",
    "        loss = train_step()\n",
    "    else:\n",
    "        loss = None\n",
    "\n",
    "    action_idx = select_action(state)\n",
    "    prev_states[env_idx] = state\n",
    "    prev_actions[env_idx] = action_idx\n",
    "\n",
    "    action = ACTIONS[action_idx]\n",
    "\n",
    "    state_t = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        q_vals = q_net(state_t)\n",
    "        chosen_q = float(q_vals[0, action_idx].item())\n",
    "\n",
    "    response = {\n",
    "        \"value\": chosen_q,\n",
    "        \"action\": {\n",
    "            \"turn\": action[\"turn\"],\n",
    "            \"throttle\": action[\"throttle\"],\n",
    "        },\n",
    "        \"debug\": {\n",
    "            \"env\": env_idx,\n",
    "            \"state\": state,\n",
    "            \"reward\": reward,\n",
    "            \"done\": done,\n",
    "            \"epsilon\": epsilon,\n",
    "            \"loss\": loss,\n",
    "            \"action_idx\": action_idx,\n",
    "            \"episode\": episode_idxs[env_idx],\n",
    "            \"episode_return\": episode_returns[env_idx],\n",
    "        },\n",
    "    }\n",
    "\n",
    "    send_json(sock, response)\n",
    "\n",
    "    if done:\n",
    "        print(f\"[ENV {env_idx}] episode {episode_idxs[env_idx]} return = {episode_returns[env_idx]:.3f}, eps={epsilon:.3f}\")\n",
    "        log_episode_to_file(env_idx, episode_idxs[env_idx], episode_returns[env_idx], epsilon)\n",
    "\n",
    "        episode_idxs[env_idx] += 1\n",
    "        episode_returns[env_idx] = 0.0\n",
    "        prev_states[env_idx] = None\n",
    "        prev_actions[env_idx] = None\n",
    "\n",
    "\n",
    "def _process_buffer_for_env(env_idx: int, sock: socket.socket) -> None:\n",
    "    buf = buffers[env_idx]\n",
    "\n",
    "    while buf:\n",
    "        buf = buf.lstrip()\n",
    "        if not buf:\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            obj, idx = decoder.raw_decode(buf)\n",
    "        except json.JSONDecodeError:\n",
    "            break\n",
    "\n",
    "        buf = buf[idx:]\n",
    "        try:\n",
    "            on_message_multi_env(env_idx, sock, obj)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in on_message for env {env_idx}: {e}\")\n",
    "\n",
    "    buffers[env_idx] = buf\n",
    "\n",
    "\n",
    "# ===========================\n",
    "#  Multi-env receive loop\n",
    "# ===========================\n",
    "\n",
    "def receive_loop_multi_env() -> None:\n",
    "    socks = connect_all_envs()\n",
    "    print(\"All envs connected, starting training loop...\")\n",
    "\n",
    "    while True:\n",
    "        if not socks:\n",
    "            print(\"All envs disconnected, stopping.\")\n",
    "            break\n",
    "\n",
    "        readable, _, _ = select.select(socks, [], [], 0.1)\n",
    "\n",
    "        for s in readable:\n",
    "            env_idx = socks.index(s)\n",
    "            try:\n",
    "                chunk = s.recv(4096)\n",
    "            except BlockingIOError:\n",
    "                continue\n",
    "\n",
    "            if not chunk:\n",
    "                print(f\"Env {env_idx} disconnected.\")\n",
    "                socks.remove(s)\n",
    "                continue\n",
    "\n",
    "            buffers[env_idx] += chunk.decode(\"utf-8\")\n",
    "            _process_buffer_for_env(env_idx, s)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_checkpoint()\n",
    "    receive_loop_multi_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfc9a52-a41b-40d9-9095-c8fae3a42f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
